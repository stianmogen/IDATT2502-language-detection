{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3bb70f1-c862-4dc3-99bb-07486721b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train.txt', 'labels.csv', 'y_train.txt', 'x_test.txt', 'y_test.txt', 'README.md', '.ipynb_checkpoints', 'urls.txt']\n",
      "cpu\n",
      "(117500, 1)\n",
      "(117500, 1)\n",
      "Example:\n",
      "LANG = est\n",
      "TEXT = Klement Gottwaldi surnukeha palsameeriti ning paigutati mausoleumi. Surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke. 1962. aastal viidi ta surnukeha mausoleumist ära ja kremeeriti. Zlíni linn kandis aastatel 1949–1989 nime Gottwaldov. Ukrainas Harkivi oblastis kandis Zmiivi linn aastatel 1976–1990 nime Gotvald.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch # Deep learning framework\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "INPUTDIR = 'input'\n",
    "print(os.listdir(f'{INPUTDIR}'))\n",
    "\n",
    "#Init random seed to get reproducible results\n",
    "seed = 1111\n",
    "random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Constants\n",
    "\n",
    "NUM_CLASSES = 235\n",
    "INPUT_DIR = \"input/\"\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"x_train.txt\"), encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "x_train = data.split('\\n')\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"x_test.txt\"), encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "x_test = data.split('\\n')\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"y_train.txt\"), encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "y_train = data.split('\\n')\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"y_test.txt\"), encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "y_test = data.split('\\n')\n",
    "\n",
    "x_train.pop(-1)\n",
    "x_test.pop(-1)\n",
    "y_train.pop(-1)\n",
    "y_test.pop(-1)\n",
    "\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns=['sentence'])\n",
    "y_train = pd.DataFrame(y_train, columns=['language'])\n",
    "\n",
    "x_test = pd.DataFrame(x_test, columns=['sentence'])\n",
    "y_test = pd.DataFrame(y_test, columns=['language'])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "print('Example:')\n",
    "print('LANG =', y_train['language'].iloc[0])\n",
    "print('TEXT =', x_train['sentence'].iloc[0])\n",
    "\n",
    "x_train_sentence = x_train['sentence']\n",
    "y_train_language = y_train['language']\n",
    "\n",
    "x_test_sentence = x_train['sentence']\n",
    "y_test_language = y_train['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f92fcf23-4791-44c8-8628-ae56c81e62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.token2idx = {}\n",
    "        self.idx2token = []\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token2idx:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = len(self.idx2token) - 1\n",
    "        return self.token2idx[token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3acf6fa0-744f-49f4-b083-0546fbc17280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 10808 UTF characters\n",
      "Labels: 235 languages\n"
     ]
    }
   ],
   "source": [
    "char_vocab = Dictionary()\n",
    "pad_token = '<pad>' # reserve index 0 for padding\n",
    "unk_token = '<unk>' # reserve index 1 for unknown token\n",
    "pad_index = char_vocab.add_token(pad_token)\n",
    "unk_index = char_vocab.add_token(unk_token)\n",
    "\n",
    "# join all the training sentences in a single string\n",
    "# and obtain the list of different characters with set\n",
    "chars = set(''.join(x_train_sentence))\n",
    "for char in sorted(chars):\n",
    "    char_vocab.add_token(char)\n",
    "print(\"Vocabulary:\", len(char_vocab), \"UTF characters\")\n",
    "\n",
    "lang_vocab = Dictionary()\n",
    "# use python set to obtain the list of languages without repetitions\n",
    "languages = set(y_train_language)\n",
    "for lang in sorted(languages):\n",
    "    lang_vocab.add_token(lang)\n",
    "print(\"Labels:\", len(lang_vocab), \"languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87af426b-78e7-43a5-b0fe-766976b39f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k -> 77\n",
      "est -> 52\n",
      "est Klement Go\n",
      "52 [45 78 71 79 71 80 86  2 41 81]\n"
     ]
    }
   ],
   "source": [
    "#From token or label to index\n",
    "print('k ->', char_vocab.token2idx['k'])\n",
    "print('est ->', lang_vocab.token2idx['est'])\n",
    "print(y_train_language[0], x_train_sentence[0][:10])\n",
    "x_train_idx = [np.array([char_vocab.token2idx[c] for c in line]) for line in x_train_sentence]\n",
    "y_train_idx = np.array([lang_vocab.token2idx[lang] for lang in y_train_language])\n",
    "print(y_train_idx[0], x_train_idx[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e733b20-b3bc-4307-a2cf-e44a3822ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117500 training samples\n",
      "94000 test samples\n",
      "23500 validation samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_test_idx = [np.array([char_vocab.token2idx[c] for c in line]) for line in x_test_sentence]\n",
    "y_test_idx = np.array([lang_vocab.token2idx[lang] for lang in y_test_language])\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test_idx, y_test_idx, test_size=0.2, random_state=42)\n",
    "train_data = [(x, y) for x, y in zip(x_train_sentence, y_train_language)]\n",
    "test_data = [(x, y) for x, y in zip(x_test, y_test)]\n",
    "val_data = [(x, y) for x, y in zip(x_val, y_val)]\n",
    "print(len(train_data), \"training samples\")\n",
    "print(len(test_data), \"test samples\")\n",
    "print(len(val_data), \"validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c450ef9-16aa-435a-8e15-a608ae34d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size, token_size):\n",
    "    \"\"\"Yield elements from data in chunks with a maximum of batch_size sequences and token_size tokens.\"\"\"\n",
    "    minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "    for ex in data:\n",
    "        seq_len = len(ex[0])\n",
    "        if seq_len > token_size:\n",
    "            ex = (ex[0][:token_size], ex[1])\n",
    "            seq_len = token_size\n",
    "        minibatch.append(ex)\n",
    "        sequences_so_far += 1\n",
    "        tokens_so_far += seq_len\n",
    "        if sequences_so_far == batch_size or tokens_so_far == token_size:\n",
    "            yield minibatch\n",
    "            minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "        elif sequences_so_far > batch_size or tokens_so_far > token_size:\n",
    "            yield minibatch[:-1]\n",
    "            minibatch, sequences_so_far, tokens_so_far = minibatch[-1:], 1, len(minibatch[-1][0])\n",
    "    if minibatch:\n",
    "        yield minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf8d4c0a-b1e6-459d-81d3-da474069544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_generator(data, batch_size, token_size, shuffle=False):\n",
    "    \"\"\"Sort within buckets, then batch, then shuffle batches.\n",
    "    Partitions data into chunks of size 100*token_size, sorts examples within\n",
    "    each chunk, then batch these examples and shuffle the batches.\n",
    "    \"\"\"\n",
    "    for p in batch_generator(data, batch_size * 100, token_size * 100):\n",
    "        p_batch = batch_generator(sorted(p, key=lambda t: len(t[0]), reverse=True), batch_size, token_size)\n",
    "        p_list = list(p_batch)\n",
    "        if shuffle:\n",
    "            for b in random.sample(p_list, len(p_list)):\n",
    "                yield b\n",
    "        else:\n",
    "            for b in p_list:\n",
    "                yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffc82e0f-b437-49f3-9a1e-6b43d8e4a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, model=\"lstm\", num_layers=1, bidirectional=False, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.model = model.lower()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = torch.nn.Embedding(input_size, embedding_size, padding_idx=pad_idx)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = torch.nn.GRU(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = torch.nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        self.h2o = torch.nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, input_lengths):\n",
    "        # T x B\n",
    "        encoded = self.embed(input)\n",
    "        # T x B x E\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(encoded, input_lengths)\n",
    "        # Packed T x B x E\n",
    "        output, _ = self.rnn(packed)\n",
    "        # Packed T x B x H\n",
    "        # Important: you may need to replace '-inf' with the default zero padding for other pooling layers\n",
    "        padded, _ = torch.nn.utils.rnn.pad_packed_sequence(output, padding_value=float('-inf'))\n",
    "        # T x B x H\n",
    "        output, _ = padded.max(dim=0)\n",
    "        # B x H\n",
    "        output = self.h2o(output)\n",
    "        # B x O\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ccefc3e-f452-439f-8a0c-c1f48fcc96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CUDA is not available. Select 'GPU On' on kernel settings\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available. Select 'GPU On' on kernel settings\")\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90a3737b-d35e-42d1-a101-2c55607c268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d561db0b-a8c0-4c25-a83e-0a4552618063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, batch_size, token_size, max_norm=1, log=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    ntokens = 0\n",
    "    niterations = 0\n",
    "    for batch in pool_generator(data, batch_size, token_size, shuffle=True):\n",
    "        # Get input and target sequences from batch\n",
    "        X = [torch.from_numpy(d[0]) for d in batch]\n",
    "        X_lengths = [x.numel() for x in X]\n",
    "        ntokens += sum(X_lengths)\n",
    "        X_lengths = torch.tensor(X_lengths, dtype=torch.long)\n",
    "        y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "        # Pad the input sequences to create a matrix\n",
    "        X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(X, X_lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)      # Gradient clipping https://www.kaggle.com/c/wili4/discussion/231378\n",
    "        optimizer.step()\n",
    "        # Training statistics\n",
    "        total_loss += loss.item()\n",
    "        ncorrect += (torch.max(output, 1)[1] == y).sum().item()\n",
    "        nsentences += y.numel()\n",
    "        niterations += 1\n",
    "    \n",
    "    total_loss = total_loss / nsentences\n",
    "    accuracy = 100 * ncorrect / nsentences\n",
    "    if log:\n",
    "        print(f'Train: wpb={ntokens//niterations}, bsz={nsentences//niterations}, num_updates={niterations}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f269739-23f0-4aa4-9d4f-eb41ee915c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, batch_size, token_size):\n",
    "    model.eval()\n",
    "    # calculate accuracy on validation set\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_generator(data, batch_size, token_size):\n",
    "            # Get input and target sequences from batch\n",
    "            X = [torch.from_numpy(d[0]) for d in batch]\n",
    "            X_lengths = torch.tensor([x.numel() for x in X], dtype=torch.long)\n",
    "            y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "            # Pad the input sequences to create a matrix\n",
    "            X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "            answer = model(X, X_lengths)\n",
    "            ncorrect += (torch.max(answer, 1)[1] == y).sum().item()\n",
    "            nsentences += y.numel()\n",
    "        dev_acc = 100 * ncorrect / nsentences\n",
    "    return dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bfbadde-d36e-4ccb-84e1-18a470ff6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embedding_size = 64\n",
    "bidirectional = False\n",
    "ntokens = len(char_vocab)\n",
    "nlabels = len(lang_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee27b456-9e02-48e8-896b-def8ac3ce1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = CharRNNClassifier(ntokens, embedding_size, hidden_size, nlabels, bidirectional=bidirectional, pad_idx=pad_index).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87693241-13c7-4cec-8fd6-34ca357fd956",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-54-a105fc4c9f3f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtrain_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mvalid_accuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Training cross-validation model for {epochs} epochs'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mt0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-53-55f7c7e7e92d>\u001B[0m in \u001B[0;36mget_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCharRNNClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mntokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbidirectional\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbidirectional\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpad_idx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpad_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    850\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 852\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    853\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m     def register_backward_hook(\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    528\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    550\u001B[0m                 \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 552\u001B[0;31m                     \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    553\u001B[0m                 \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    848\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[1;32m    849\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[0;32m--> 850\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    851\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    852\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    164\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[1;32m    165\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_cuda_getDeviceCount'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    167\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m             raise AssertionError(\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "batch_size, token_size = 256, 200000\n",
    "epochs = 25\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "model, optimizer = get_model()\n",
    "print(f'Training cross-validation model for {epochs} epochs')\n",
    "t0 = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    acc = train(model, optimizer, train_data, batch_size, token_size, log=epoch==1)\n",
    "    train_accuracy.append(acc)\n",
    "    print(f'| epoch {epoch:03d} | train accuracy={acc:.1f}% ({time.time() - t0:.0f}s)')\n",
    "    acc = validate(model, val_data, batch_size, token_size)\n",
    "    valid_accuracy.append(acc)\n",
    "    print(f'| epoch {epoch:03d} | valid accuracy={acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43690b3c-6582-40f3-80c4-463a7e46f3ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-55-e92fe3fab3ab>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_parameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{name:20} {param.numel()} {list(param.shape)}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'TOTAL                {sum(p.numel() for p in model.parameters())}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name:20} {param.numel()} {list(param.shape)}')\n",
    "print(f'TOTAL                {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6ce00b4-0737-49fb-841a-0b9b84b97070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(train_accuracy)+1), train_accuracy)\n",
    "plt.plot(range(1, len(valid_accuracy)+1), valid_accuracy)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd1ba4-6e58-4322-b4da-b8008c8804c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}